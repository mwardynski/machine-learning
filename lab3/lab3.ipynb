{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "      \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.probs = None\n",
    "      \n",
    "    def fit(self, X, y):\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        self.probs = np.zeros(len(values))\n",
    "        self.mean = np.zeros((len(values), X.shape[1]))\n",
    "        self.std = np.zeros((len(values), X.shape[1]))\n",
    "        \n",
    "        for i, value in enumerate(values):\n",
    "            self.probs[value] = counts[i]/len(y)\n",
    "\n",
    "        for label in range(len(self.probs)):\n",
    "            indices = np.where(y == label)[0]\n",
    "            relevant_samples = X[indices]\n",
    "            for feat in range(relevant_samples.shape[1]):\n",
    "                feat_mean = np.mean(relevant_samples[:, feat])\n",
    "                feat_std = np.std(relevant_samples[:, feat])\n",
    "              \n",
    "                self.mean[label][feat] = feat_mean\n",
    "                self.std[label][feat] = feat_std       \n",
    "        return self\n",
    "      \n",
    "    def predict(self, X):\n",
    "        labels = []\n",
    "        for x in X:\n",
    "            selected_k = -1\n",
    "            max_prob_for_k = 0\n",
    "            for k in range(len(self.probs)):\n",
    "                sum = 0\n",
    "                for i in range(self.mean.shape[1]):\n",
    "                    prob_xi_ck = 1/math.sqrt(2*math.pi*self.std[k][i])*math.exp(-((x[i]-self.mean[k][i])**2)/(2*self.std[k][i]))\n",
    "                    sum += prob_xi_ck\n",
    "                prob_k = math.log(self.probs[k]) + sum\n",
    "                if(max_prob_for_k < prob_k):\n",
    "                    max_prob_for_k = prob_k\n",
    "                    selected_k = k\n",
    "            labels.append(selected_k)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg-values -> precision: 0.946031746031746, recall: 0.9333333333333333, f1 score: 0.9333333333333333\n",
      "avg-values -> precision: 0.9575, recall: 0.95, f1 score: 0.9501039501039501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "my_gnb = GaussianNaiveBayes()\n",
    "my_gnb.fit(X_train, y_train)\n",
    "y_pred = my_gnb.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BernoulliNaiveBayes:\n",
    "      \n",
    "#     def __init__(self):\n",
    "#         self.probs = None\n",
    "#         self.feats = None\n",
    "      \n",
    "#     def fit(self, X, y):\n",
    "#         values, counts = np.unique(y, return_counts=True)\n",
    "#         self.probs = counts/len(y)\n",
    "        \n",
    "#         self.feats = np.zeros((len(self.probs), X.shape[1]))\n",
    "#         for i, k in enumerate(values):\n",
    "#             indices = np.where(y == k)\n",
    "#             relevant_samples = X[indices]\n",
    "#             self.feats[i, :] = (np.sum(relevant_samples, axis=0) + 1) / (relevant_samples.shape[0] + 2)\n",
    "\n",
    "        \n",
    "#         return self\n",
    "      \n",
    "#     def predict(self, X):\n",
    "#         labels = []\n",
    "\n",
    "#         for x in X:\n",
    "#             x = x.toarray().flatten()\n",
    "#             selected_k = -1\n",
    "#             max_prob_for_k = 0\n",
    "#             for k in range(len(self.probs)):\n",
    "#                 sum = 0\n",
    "#                 for i in range(x.shape[0]):\n",
    "#                     prob_xi_ck = self.feats[k][i]**x[i]*(1-self.feats[k][i])**(1-x[i])\n",
    "#                     sum += prob_xi_ck\n",
    "#                 prob_k = math.log(self.probs[k]) + sum\n",
    "#                 if(max_prob_for_k < prob_k):\n",
    "#                     max_prob_for_k = prob_k\n",
    "#                     selected_k = k\n",
    "#             labels.append(selected_k)\n",
    "\n",
    "#         return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BernoulliNaiveBayes:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.probs = None\n",
    "        self.feats = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        self.probs = counts / len(y)\n",
    "        self.feats = np.zeros((len(self.probs), X.shape[1]))\n",
    "\n",
    "        for i, k in enumerate(values):\n",
    "            indices = np.where(y == k)\n",
    "            relevant_samples = X[indices]\n",
    "            \n",
    "            sum = (np.sum(relevant_samples, axis=0) + 1) # +1 for Laplace smoothing\n",
    "            self.feats[i, :] = sum / (relevant_samples.shape[0] + 2) # +2 for Laplace smoothing\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, calc_logs=True):\n",
    "        labels = []\n",
    "\n",
    "        # X = X.toarray().flatten()\n",
    "        for x_sparse in X:\n",
    "            x = x_sparse.toarray().flatten()\n",
    "            selected_k = -1\n",
    "            max_prob_for_k = -np.inf\n",
    "\n",
    "            for k in range(len(self.probs)):\n",
    "\n",
    "                prob_k = self.calculate_prob_logs(k, x) if calc_logs else self.calculate_prob_directly(k, x)\n",
    "\n",
    "                if prob_k > max_prob_for_k:\n",
    "                    max_prob_for_k = prob_k\n",
    "                    selected_k = k\n",
    "\n",
    "            labels.append(selected_k)\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    def calculate_prob_directly(self, k, x):\n",
    "        prob_xi_ck = self.feats[k] ** x * (1 - self.feats[k]) ** (1 - x)\n",
    "        prob_k = self.probs[k] * np.prod(prob_xi_ck)\n",
    "        return prob_k\n",
    "    \n",
    "    def calculate_prob_logs(self, k, x):\n",
    "        epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "        \n",
    "        # Log-likelihood: sum of log probabilities instead of multiplying probabilities directly\n",
    "        log_prob_xi_ck = x * np.log(self.feats[k] + epsilon) + (1 - x) * np.log(1 - self.feats[k] + epsilon)\n",
    "\n",
    "        # log_likelihood = x_dense * self.feature_log_prob_[k] + (1 - x_dense) * np.log(1 - np.exp(self.feature_log_prob_[k]))\n",
    "                        \n",
    "        # Calculate total log-probability for class k\n",
    "        log_prob_k = np.log(self.probs[k] + epsilon) + np.sum(log_prob_xi_ck)\n",
    "\n",
    "        # log_prob_k = self.class_log_prior_[k] + np.sum(log_likelihood)\n",
    "\n",
    "        return log_prob_k\n",
    "\n",
    "    # def calculate_prob_logs(self, k, x):\n",
    "    #     log_likelihood = x * np.log(self.feats[k]) + (1 - x) * np.log(1 - self.feats[k])  \n",
    "    #     log_prob_k = np.log(self.probs[k]) + np.sum(log_likelihood)\n",
    "    #     return log_prob_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_data = newsgroups.data\n",
    "y = newsgroups.target\n",
    "\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_data)\n",
    "X = cnt_vect.transform(X_data)\n",
    "X.data[X.data>1] = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg-values -> precision: 0.6604541322202436, recall: 0.4917771883289125, f1 score: 0.46683201136660324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg-values -> precision: 0.5756197639939095, recall: 0.39283819628647215, f1 score: 0.3815098191772453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNaiveBayes()\n",
    "\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test, calc_logs=False)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNaiveBayes()\n",
    "\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BernoulliNaiveBayesGoodLogs:\n",
    "      \n",
    "    def __init__(self):\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "      \n",
    "    def fit(self, X, y):\n",
    "        # Get the unique class values and their counts\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Compute the log of class priors\n",
    "        self.class_log_prior_ = np.log(counts / len(y))  # Log of prior probabilities\n",
    "        \n",
    "        # Initialize feature log probabilities\n",
    "        self.feature_log_prob_ = np.zeros((len(self.class_log_prior_), X.shape[1]))\n",
    "\n",
    "        for i, k in enumerate(values):\n",
    "            indices = np.where(y == k)\n",
    "            relevant_samples = X[indices]\n",
    "            \n",
    "            # Laplace smoothing: Add 1 to feature count, add 2 to denominator for smoothing\n",
    "            smoothed_counts = (np.sum(relevant_samples, axis=0) + 1)\n",
    "            self.feature_log_prob_[i, :] = np.log(smoothed_counts / (relevant_samples.shape[0] + 2))\n",
    "        \n",
    "        return self\n",
    "      \n",
    "    def predict(self, X):\n",
    "        labels = []\n",
    "\n",
    "        for x in X:\n",
    "            x_dense = x.toarray().flatten()  # Convert to dense array\n",
    "            selected_k = -1\n",
    "            max_log_prob = -np.inf  # Use negative infinity for log probabilities\n",
    "\n",
    "            for k in range(len(self.class_log_prior_)):\n",
    "                # Calculate log likelihood for each class k\n",
    "                log_likelihood = x_dense * self.feature_log_prob_[k] + (1 - x_dense) * np.log(1 - np.exp(self.feature_log_prob_[k]))\n",
    "                \n",
    "                # Sum log likelihood and class prior (log of prior probability)\n",
    "                log_prob_k = self.class_log_prior_[k] + np.sum(log_likelihood)\n",
    "\n",
    "                # Select the class with the highest log probability\n",
    "                if log_prob_k > max_log_prob:\n",
    "                    max_log_prob = log_prob_k\n",
    "                    selected_k = k\n",
    "\n",
    "            labels.append(selected_k)\n",
    "\n",
    "        return labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m bnbgl \u001b[38;5;241m=\u001b[39m BernoulliNaiveBayesGoodLogs()\n\u001b[1;32m      3\u001b[0m bnbgl\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbnbgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m precision_avg, recall_avg, f1_score_avg, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg-values -> precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, f1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score_avg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[88], line 45\u001b[0m, in \u001b[0;36mBernoulliNaiveBayesGoodLogs.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m log_prob_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_[k] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(log_likelihood)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Select the class with the highest log probability\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlog_prob_k\u001b[49m \u001b[38;5;241m>\u001b[39m max_log_prob:\n\u001b[1;32m     46\u001b[0m     max_log_prob \u001b[38;5;241m=\u001b[39m log_prob_k\n\u001b[1;32m     47\u001b[0m     selected_k \u001b[38;5;241m=\u001b[39m k\n",
      "File \u001b[0;32m<stringsource>:69\u001b[0m, in \u001b[0;36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1429\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._line_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1471\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1278\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1906\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bnbgl = BernoulliNaiveBayesGoodLogs()\n",
    "\n",
    "bnbgl.fit(X_train, y_train)\n",
    "y_pred = bnbgl.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BernoulliNaiveBayesNew:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.probs = None\n",
    "        self.feats = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        self.probs = counts / len(y)\n",
    "        self.feats = np.zeros((len(self.probs), X.shape[1]))\n",
    "\n",
    "        for i, k in enumerate(values):\n",
    "            indices = np.where(y == k)\n",
    "            relevant_samples = X[indices]\n",
    "            \n",
    "            smoothed_counts = (np.sum(relevant_samples, axis=0) + 1) # +1 for Laplace smoothing\n",
    "            self.feats[i, :] = smoothed_counts / (relevant_samples.shape[0] + 2) # +2 for Laplace smoothing\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, calc_logs=True):\n",
    "        labels = []\n",
    "\n",
    "        for x_sparse in X:\n",
    "            x = x_sparse.toarray().flatten()  # Convert sparse row to dense array\n",
    "            selected_k = -1\n",
    "            max_prob_for_k = -np.inf  # Start with negative infinity for log probabilities\n",
    "\n",
    "            for k in range(len(self.probs)):\n",
    "                # Calculate probability using logs for numerical stability\n",
    "                prob_k = self.calculate_prob_logs(k, x) if calc_logs else self.calculate_prob_directly(k, x)\n",
    "\n",
    "                if prob_k > max_prob_for_k:\n",
    "                    max_prob_for_k = prob_k\n",
    "                    selected_k = k\n",
    "\n",
    "            labels.append(selected_k)\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    def calculate_prob_directly(self, k, x):\n",
    "        # Old method (not recommended)\n",
    "        prob_xi_ck = self.feats[k] ** x * (1 - self.feats[k]) ** (1 - x)\n",
    "        prob_k = self.probs[k] * np.prod(prob_xi_ck)\n",
    "        return prob_k\n",
    "    \n",
    "    def calculate_prob_logs(self, k, x):\n",
    "        epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "\n",
    "        # Log-likelihood: sum of log probabilities\n",
    "        log_prob_xi_ck = x * np.log(self.feats[k] + epsilon) + (1 - x) * np.log(1 - self.feats[k] + epsilon)\n",
    "        \n",
    "        # Calculate total log-probability for class k\n",
    "        log_prob_k = np.log(self.probs[k] + epsilon) + np.sum(log_prob_xi_ck)\n",
    "        \n",
    "        return log_prob_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg-values -> precision: 0.0, recall: 0.0, f1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bnbnew = BernoulliNaiveBayesNew()\n",
    "\n",
    "bnbnew.fit(X_train, y_train)\n",
    "y_pred = bnbnew.predict(X_test)\n",
    "\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Breast Cancer Wisconsin dataset\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Get the features and target\n",
    "X = cancer.data  # Feature matrix\n",
    "y = cancer.target  # Target labels (0 = malignant, 1 = benign)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "my_gnb = GaussianNaiveBayes()\n",
    "my_gnb.fit(X_train, y_train)\n",
    "y_pred = my_gnb.predict(X_test)\n",
    "precision_avg, recall_avg, f1_score_avg, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print(f'avg-values -> precision: {precision_avg}, recall: {recall_avg}, f1 score: {f1_score_avg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
