{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcin Wardyński  \n",
    "wtorek, 9:45\n",
    "\n",
    "## Laboratorium 7\n",
    "### 7.4 AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import lab7_utils as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(tf.keras.Model):\n",
    "  def __init__(self, latent_dim, mid_dim):\n",
    "    super(SimpleAutoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.mid_dim = mid_dim    \n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(784,)),\n",
    "            tf.keras.layers.Dense(mid_dim, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(latent_dim, activation=tf.nn.relu),\n",
    "        ]\n",
    "    )\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(mid_dim, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(units=28*28, activation=tf.nn.sigmoid),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = utils.get_dataset_for_ae(utils.Dataset_Select.MNIST.value, with_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = SimpleAutoencoder(784, 196, 256)\n",
    "autoencoder = tf.keras.Sequential([autoencoder.encoder, autoencoder.decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss=keras.losses.BinaryCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 10.1245 - val_loss: 0.2633\n",
      "Epoch 2/10\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2638 - val_loss: 0.2631\n",
      "Epoch 3/10\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2636 - val_loss: 0.2631\n",
      "Epoch 4/10\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2638 - val_loss: 0.2629\n",
      "Epoch 5/10\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2643 - val_loss: 0.2630\n",
      "Epoch 6/10\n",
      "\u001b[1m 151/1608\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.2632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrozenEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(tf.keras.Model):\n",
    "  def __init__(self, inout_dim, latent_dim, mid_dim):\n",
    "    super(SimpleAutoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.mid_dim = mid_dim    \n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(inout_dim, )),\n",
    "            tf.keras.layers.Dense(mid_dim, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(latent_dim, activation=tf.nn.relu),\n",
    "        ]\n",
    "    )\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(mid_dim, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(units=inout_dim, activation=tf.nn.sigmoid),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded    \n",
    "\n",
    "def create_simple_ae_as_sequence(inout_dim, latent_dim, mid_dim):\n",
    "  model =  SimpleAutoencoder(inout_dim, latent_dim, mid_dim)\n",
    "  return tf.keras.Sequential([model.encoder, model.decoder])\n",
    "\n",
    "def create_simple_ae_from_params(params):\n",
    "  return SimpleAutoencoder(params[\"model__inout_dim\"], params[\"model__latent_dim\"], params[\"model__mid_dim\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate_autoencoder(dataset_name, params, create_plain_ae_fun, create_ae_from_params_fun):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(dataset_name=dataset_name, with_val=False)\n",
    "\n",
    "    keras_reg = KerasRegressor(\n",
    "        model=create_plain_ae_fun,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        optimizer__learning_rate=0.001,\n",
    "        model__inout_dim=784,\n",
    "        model__latent_dim=128,\n",
    "        model__mid_dim=256,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    grid_search = GridSearchCV(keras_reg, params, refit=False, cv=7, n_jobs=-1)\n",
    "    grid_search.fit(X_train, X_train)\n",
    "\n",
    "    print(grid_search.best_score_, grid_search.best_params_)\n",
    "\n",
    "    X_train_s, X_val_s, _, _, _, _ = utils.get_dataset_for_ae(dataset_name=dataset_name, with_val=True)\n",
    "\n",
    "    ae = create_ae_from_params_fun(grid_search.best_params_)\n",
    "    ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=grid_search.best_params_[\"optimizer__learning_rate\"]), loss=keras.losses.BinaryCrossentropy)\n",
    "    ae.fit(X_train_s, X_train_s,\n",
    "                epochs=grid_search.best_params_[\"epochs\"],\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val_s, X_val_s))\n",
    "    \n",
    "    return ae\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-01-02 02:21:28.241627: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0] vs. [784,512]\n",
      "\t [[{{function_node __inference_one_step_on_data_985794}}{{node adam/truediv_1}}]]\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "1 fits failed out of a total of 252.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node adam/truediv_1 defined at (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/joblib/parallel.py\", line 598, in __call__\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 368, in fit\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 216, in function\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 129, in multi_step_on_iterator\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 78, in train_step\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py\", line 344, in apply_gradients\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py\", line 409, in apply\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py\", line 472, in _backend_apply_gradients\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 120, in _backend_update_step\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 134, in _distributed_tf_update_step\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 131, in apply_grad_to_update_var\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/optimizers/adam.py\", line 147, in update_step\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/ops/numpy.py\", line 5948, in divide\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/sparse.py\", line 780, in sparse_wrapper\n",
      "\n",
      "  File \"/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/numpy.py\", line 2368, in divide\n",
      "\n",
      "Incompatible shapes: [0] vs. [784,512]\n",
      "\t [[{{node adam/truediv_1}}]] [Op:__inference_multi_step_on_iterator_985854]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [ 2.27487416e-01 -2.65385130e+00  1.68704116e-01 -3.74537242e-02\n",
      " -4.96803094e+00 -4.18607958e+00 -1.91028776e-01  3.09371208e-02\n",
      "             nan  5.93948688e-01 -1.41421730e+00 -1.04608441e-01\n",
      " -2.76195082e-01 -4.85494710e-02 -3.83203365e-01  4.62615714e-01\n",
      "  1.46808589e-01  1.47721359e-01  6.37079465e-01 -2.68531624e+01\n",
      " -1.71532243e+00  6.74276266e-01 -5.27264317e-01  2.35859020e-01\n",
      "  6.58498798e-01  1.21628641e-01 -1.71820281e+01  6.72968966e-01\n",
      "  3.80208605e-01 -3.76682978e-01  7.12966146e-01  1.28090431e-01\n",
      " -1.96868662e+01  6.55012107e-01 -1.05140398e+00  4.48259943e-03]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712966146204136 {'epochs': 40, 'model__inout_dim': 784, 'model__latent_dim': 192, 'model__mid_dim': 384, 'optimizer__learning_rate': 0.001}\n",
      "Epoch 1/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.1542 - val_loss: 0.0820\n",
      "Epoch 2/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0786 - val_loss: 0.0754\n",
      "Epoch 3/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0735 - val_loss: 0.0734\n",
      "Epoch 4/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0714 - val_loss: 0.0722\n",
      "Epoch 5/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0701 - val_loss: 0.0712\n",
      "Epoch 6/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0695 - val_loss: 0.0698\n",
      "Epoch 7/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0686 - val_loss: 0.0711\n",
      "Epoch 8/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0681 - val_loss: 0.0694\n",
      "Epoch 9/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0680 - val_loss: 0.0692\n",
      "Epoch 10/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0678 - val_loss: 0.0687\n",
      "Epoch 11/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0671 - val_loss: 0.0680\n",
      "Epoch 12/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0669 - val_loss: 0.0681\n",
      "Epoch 13/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0669 - val_loss: 0.0682\n",
      "Epoch 14/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0667 - val_loss: 0.0680\n",
      "Epoch 15/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0665 - val_loss: 0.0673\n",
      "Epoch 16/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0665 - val_loss: 0.0673\n",
      "Epoch 17/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0662 - val_loss: 0.0678\n",
      "Epoch 18/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0661 - val_loss: 0.0669\n",
      "Epoch 19/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0660 - val_loss: 0.0671\n",
      "Epoch 20/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0661 - val_loss: 0.0676\n",
      "Epoch 21/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0659 - val_loss: 0.0675\n",
      "Epoch 22/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0658 - val_loss: 0.0673\n",
      "Epoch 23/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0659 - val_loss: 0.0675\n",
      "Epoch 24/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0658 - val_loss: 0.0672\n",
      "Epoch 25/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0657 - val_loss: 0.0668\n",
      "Epoch 26/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 0.0658 - val_loss: 0.0671\n",
      "Epoch 27/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0654 - val_loss: 0.0669\n",
      "Epoch 28/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0655 - val_loss: 0.0663\n",
      "Epoch 29/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0654 - val_loss: 0.0671\n",
      "Epoch 30/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0654 - val_loss: 0.0672\n",
      "Epoch 31/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0655 - val_loss: 0.0675\n",
      "Epoch 32/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0653 - val_loss: 0.0667\n",
      "Epoch 33/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0653 - val_loss: 0.0673\n",
      "Epoch 34/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0653 - val_loss: 0.0664\n",
      "Epoch 35/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0651 - val_loss: 0.0661\n",
      "Epoch 36/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0653 - val_loss: 0.0663\n",
      "Epoch 37/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0652 - val_loss: 0.0664\n",
      "Epoch 38/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0651 - val_loss: 0.0664\n",
      "Epoch 39/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0651 - val_loss: 0.0662\n",
      "Epoch 40/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0651 - val_loss: 0.0664\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'model__inout_dim': [784],\n",
    "    'model__latent_dim': [10, 64, 128, 192],\n",
    "    'model__mid_dim': [256, 384, 512],\n",
    "    'optimizer__learning_rate': [0.001, 0.005, 0.01],\n",
    "    'epochs': [40]\n",
    "}\n",
    "\n",
    "ae = evaluate_autoencoder(utils.Dataset_Select.MNIST.value, param_grid, create_simple_ae_as_sequence, create_simple_ae_from_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "0.712966146204136 {'epochs': 40, 'model__inout_dim': 784, 'model__latent_dim': 192, 'model__mid_dim': 384, 'optimizer__learning_rate': 0.001}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SimpleAutoencoder name=simple_autoencoder_88, built=True>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.92      0.91      0.92      1032\n",
      "           3       0.89      0.91      0.90      1010\n",
      "           4       0.92      0.93      0.93       982\n",
      "           5       0.91      0.87      0.89       892\n",
      "           6       0.95      0.96      0.95       958\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.88      0.90      0.89       974\n",
      "           9       0.91      0.90      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "frozen_encoder = FrozenEncoder(encoder=ae_trained.encoder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(dataset_name=utils.Dataset_Select.MNIST.value, with_val=False)\n",
    "\n",
    "pipeline_log_reg = Pipeline([\n",
    "    ('frozen_encoder', frozen_encoder),\n",
    "    ('log_reg', LogisticRegression(max_iter=2000, solver=\"newton-cg\"))\n",
    "])\n",
    "\n",
    "pipeline_log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_log_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.3514 - val_loss: 0.2958\n",
      "Epoch 2/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2938 - val_loss: 0.2903\n",
      "Epoch 3/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2892 - val_loss: 0.2895\n",
      "Epoch 4/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2869 - val_loss: 0.2863\n",
      "Epoch 5/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2859 - val_loss: 0.2857\n",
      "Epoch 6/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2845 - val_loss: 0.2845\n",
      "Epoch 7/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2828 - val_loss: 0.2841\n",
      "Epoch 8/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2836 - val_loss: 0.2839\n",
      "Epoch 9/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2829 - val_loss: 0.2832\n",
      "Epoch 10/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2821 - val_loss: 0.2829\n",
      "Epoch 11/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2821 - val_loss: 0.2828\n",
      "Epoch 12/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2819 - val_loss: 0.2824\n",
      "Epoch 13/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2814 - val_loss: 0.2822\n",
      "Epoch 14/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2808 - val_loss: 0.2822\n",
      "Epoch 15/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2813 - val_loss: 0.2820\n",
      "Epoch 16/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2800 - val_loss: 0.2815\n",
      "Epoch 17/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2801 - val_loss: 0.2818\n",
      "Epoch 18/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2809 - val_loss: 0.2818\n",
      "Epoch 19/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2807 - val_loss: 0.2813\n",
      "Epoch 20/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2802 - val_loss: 0.2815\n",
      "Epoch 21/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2808 - val_loss: 0.2816\n",
      "Epoch 22/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2800 - val_loss: 0.2814\n",
      "Epoch 23/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2798 - val_loss: 0.2813\n",
      "Epoch 24/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2805 - val_loss: 0.2812\n",
      "Epoch 25/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2801 - val_loss: 0.2812\n",
      "Epoch 26/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2794 - val_loss: 0.2812\n",
      "Epoch 27/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2796 - val_loss: 0.2807\n",
      "Epoch 28/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2792 - val_loss: 0.2809\n",
      "Epoch 29/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2787 - val_loss: 0.2808\n",
      "Epoch 30/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2787 - val_loss: 0.2811\n",
      "Epoch 31/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2794 - val_loss: 0.2813\n",
      "Epoch 32/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2795 - val_loss: 0.2813\n",
      "Epoch 33/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2786 - val_loss: 0.2807\n",
      "Epoch 34/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2781 - val_loss: 0.2809\n",
      "Epoch 35/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.2792 - val_loss: 0.2809\n",
      "Epoch 36/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2791 - val_loss: 0.2808\n",
      "Epoch 37/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2795 - val_loss: 0.2805\n",
      "Epoch 38/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2784 - val_loss: 0.2806\n",
      "Epoch 39/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2785 - val_loss: 0.2807\n",
      "Epoch 40/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.2790 - val_loss: 0.2809\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step  \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.75      0.76      0.76      1000\n",
      "           3       0.85      0.88      0.86      1000\n",
      "           4       0.74      0.75      0.75      1000\n",
      "           5       0.95      0.91      0.93      1000\n",
      "           6       0.62      0.58      0.60      1000\n",
      "           7       0.91      0.94      0.92      1000\n",
      "           8       0.95      0.97      0.96      1000\n",
      "           9       0.93      0.94      0.93      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train_s, X_val_s, _, _, _, _ = utils.get_dataset_for_ae(dataset_name=utils.Dataset_Select.F_MNIST.value, with_val=True)\n",
    "\n",
    "simple_ae = SimpleAutoencoder(inout_dim=784, latent_dim=10, mid_dim=384)\n",
    "simple_ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy)\n",
    "simple_ae.fit(X_train_s, X_train_s,\n",
    "                epochs=40,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val_s, X_val_s))\n",
    "\n",
    "frozen_encoder = FrozenEncoder(encoder=simple_ae)\n",
    "\n",
    "X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(dataset_name=utils.Dataset_Select.F_MNIST.value, with_val=False)\n",
    "\n",
    "pipeline_log_reg = Pipeline([\n",
    "    ('frozen_encoder', frozen_encoder),\n",
    "    ('log_reg', LogisticRegression(max_iter=5000, solver=\"newton-cg\"))\n",
    "])\n",
    "\n",
    "pipeline_log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_log_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       980\n",
      "           1       0.99      0.98      0.98      1135\n",
      "           2       0.93      0.95      0.94      1032\n",
      "           3       0.92      0.95      0.93      1010\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.96      0.92      0.94       892\n",
      "           6       0.96      0.97      0.97       958\n",
      "           7       0.96      0.93      0.95      1028\n",
      "           8       0.93      0.92      0.93       974\n",
      "           9       0.94      0.93      0.93      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline_rand_frst = Pipeline([\n",
    "    ('frozen_encoder', frozen_encoder),\n",
    "    ('rand_frst', RandomForestClassifier(n_estimators=250, random_state=seed))\n",
    "])\n",
    "\n",
    "pipeline_rand_frst.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_rand_frst.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(ConvAutoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(784,)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim),\n",
    "        ]\n",
    "    )\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same',\n",
    "                activation='sigmoid'),\n",
    "            tf.keras.layers.Reshape(target_shape=(784,))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(ConvAutoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(784,)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(384, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(latent_dim)\n",
    "        ]\n",
    "    )\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same',\n",
    "                activation='sigmoid'),\n",
    "            tf.keras.layers.Reshape(target_shape=(784,))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "def create_conv_ae_as_sequence(latent_dim):\n",
    "  model =  ConvAutoencoder(latent_dim)\n",
    "  return tf.keras.Sequential([model.encoder, model.decoder])\n",
    "\n",
    "def create_conv_ae_from_params(params):\n",
    "  return SimpleAutoencoder(params[\"model__latent_dim\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_img = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "encoded = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Reshape((7, 7, 64))(encoded)\n",
    "x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(ConvAutoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim),\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape((7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "encoded = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Reshape((7, 7, 64))(encoded)\n",
    "x = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "conv_autoencoder = tf.keras.models.Model(inputs=input_img, outputs=decoded)\n",
    "\n",
    "conv_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(utils.Dataset_Select.F_MNIST.value, with_val=False)\n",
    "X_train_reshaped = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "conv_ae = ConvAutoencoder(256)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "conv_ae.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_conv = conv_ae.fit(\n",
    "    X_train_reshaped, X_train_reshaped,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "plt.plot(history_conv.history['loss'], label='Train Loss')\n",
    "plt.plot(history_conv.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Trenowanie konwolucyjnego Autoencodera - MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Zakodowane cechy (ConvAE) - kształt: (60000, 256) (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = conv_ae.encoder\n",
    "\n",
    "X_train_conv_encoded = encoder.predict(X_train_reshaped)\n",
    "X_test_conv_encoded = encoder.predict(X_test_reshaped)\n",
    "\n",
    "print(\"Zakodowane cechy (ConvAE) - kształt:\", X_train_conv_encoded.shape, X_test_conv_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_conv_lr = LogisticRegression(solver='newton-cg', max_iter=200)\n",
    "clf_conv_lr.fit(X_train_conv_encoded, y_train)\n",
    "y_pred_conv_lr = clf_conv_lr.predict(X_test_conv_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== LogisticRegression (ConvAE) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      1000\n",
      "           1       0.99      0.98      0.98      1000\n",
      "           2       0.80      0.83      0.82      1000\n",
      "           3       0.88      0.91      0.90      1000\n",
      "           4       0.80      0.81      0.81      1000\n",
      "           5       0.97      0.97      0.97      1000\n",
      "           6       0.72      0.66      0.69      1000\n",
      "           7       0.95      0.97      0.96      1000\n",
      "           8       0.97      0.97      0.97      1000\n",
      "           9       0.97      0.96      0.97      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Accuracy (ConvAE + LogisticRegression): 0.8900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"==== LogisticRegression (ConvAE) ====\")\n",
    "print(classification_report(y_test, y_pred_conv_lr))\n",
    "acc_conv_lr = accuracy_score(y_test, y_pred_conv_lr)\n",
    "print(f\"Accuracy (ConvAE + LogisticRegression): {acc_conv_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent 10:\n",
    "\n",
    "==== LogisticRegression (ConvAE) ====\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.78      0.76      1000\n",
    "           1       0.96      0.94      0.95      1000\n",
    "           2       0.64      0.60      0.62      1000\n",
    "           3       0.76      0.84      0.80      1000\n",
    "           4       0.61      0.68      0.64      1000\n",
    "           5       0.91      0.89      0.90      1000\n",
    "           6       0.45      0.34      0.39      1000\n",
    "           7       0.87      0.89      0.88      1000\n",
    "           8       0.92      0.94      0.93      1000\n",
    "           9       0.91      0.92      0.92      1000\n",
    "\n",
    "    accuracy                           0.78     10000\n",
    "   macro avg       0.78      0.78      0.78     10000\n",
    "weighted avg       0.78      0.78      0.78     10000\n",
    "\n",
    "Accuracy (ConvAE + LogisticRegression): 0.7834\n",
    "\n",
    "Dense Latent 512:\n",
    "\n",
    "```\n",
    "==== LogisticRegression (ConvAE) ====\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.85      0.84      1000\n",
    "           1       0.99      0.98      0.98      1000\n",
    "           2       0.83      0.85      0.84      1000\n",
    "           3       0.89      0.91      0.90      1000\n",
    "           4       0.82      0.83      0.83      1000\n",
    "           5       0.97      0.97      0.97      1000\n",
    "           6       0.74      0.68      0.71      1000\n",
    "           7       0.95      0.97      0.96      1000\n",
    "           8       0.97      0.98      0.98      1000\n",
    "           9       0.98      0.96      0.97      1000\n",
    "\n",
    "    accuracy                           0.90     10000\n",
    "   macro avg       0.90      0.90      0.90     10000\n",
    "weighted avg       0.90      0.90      0.90     10000\n",
    "\n",
    "Accuracy (ConvAE + LogisticRegression): 0.8979\n",
    "```\n",
    "\n",
    "\n",
    "No mod:\n",
    "\n",
    "```\n",
    "==== LogisticRegression (ConvAE) ====\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.87      0.85      1000\n",
    "           1       0.99      0.98      0.99      1000\n",
    "           2       0.85      0.85      0.85      1000\n",
    "           3       0.90      0.91      0.91      1000\n",
    "           4       0.84      0.86      0.85      1000\n",
    "           5       0.98      0.98      0.98      1000\n",
    "           6       0.77      0.72      0.74      1000\n",
    "           7       0.96      0.98      0.97      1000\n",
    "           8       0.98      0.97      0.98      1000\n",
    "           9       0.98      0.97      0.97      1000\n",
    "\n",
    "    accuracy                           0.91     10000\n",
    "   macro avg       0.91      0.91      0.91     10000\n",
    "weighted avg       0.91      0.91      0.91     10000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ae = ConvAutoencoder(10)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "conv_ae.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy())\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utils.get_dataset_for_ae(utils.Dataset_Select.F_MNIST.value, with_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 35ms/step - loss: 0.3478 - val_loss: 0.2874\n",
      "Epoch 2/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2846 - val_loss: 0.2833\n",
      "Epoch 3/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 34ms/step - loss: 0.2796 - val_loss: 0.2790\n",
      "Epoch 4/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 34ms/step - loss: 0.2781 - val_loss: 0.2778\n",
      "Epoch 5/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 34ms/step - loss: 0.2762 - val_loss: 0.2768\n",
      "Epoch 6/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 33ms/step - loss: 0.2755 - val_loss: 0.2762\n",
      "Epoch 7/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 33ms/step - loss: 0.2753 - val_loss: 0.2760\n",
      "Epoch 8/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2743 - val_loss: 0.2751\n",
      "Epoch 9/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 34ms/step - loss: 0.2741 - val_loss: 0.2748\n",
      "Epoch 10/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2732 - val_loss: 0.2744\n",
      "Epoch 11/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2734 - val_loss: 0.2743\n",
      "Epoch 12/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2725 - val_loss: 0.2749\n",
      "Epoch 13/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2731 - val_loss: 0.2742\n",
      "Epoch 14/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 35ms/step - loss: 0.2725 - val_loss: 0.2741\n",
      "Epoch 15/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 35ms/step - loss: 0.2732 - val_loss: 0.2737\n",
      "Epoch 16/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 35ms/step - loss: 0.2719 - val_loss: 0.2737\n",
      "Epoch 17/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 34ms/step - loss: 0.2724 - val_loss: 0.2734\n",
      "Epoch 18/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 35ms/step - loss: 0.2730 - val_loss: 0.2741\n",
      "Epoch 19/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 35ms/step - loss: 0.2719 - val_loss: 0.2732\n",
      "Epoch 20/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 34ms/step - loss: 0.2714 - val_loss: 0.2737\n",
      "Epoch 21/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 34ms/step - loss: 0.2716 - val_loss: 0.2730\n",
      "Epoch 22/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 33ms/step - loss: 0.2713 - val_loss: 0.2734\n",
      "Epoch 23/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 34ms/step - loss: 0.2714 - val_loss: 0.2734\n",
      "Epoch 24/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2711 - val_loss: 0.2729\n",
      "Epoch 25/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2710 - val_loss: 0.2730\n",
      "Epoch 26/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2709 - val_loss: 0.2728\n",
      "Epoch 27/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2716 - val_loss: 0.2729\n",
      "Epoch 28/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2706 - val_loss: 0.2729\n",
      "Epoch 29/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2707 - val_loss: 0.2728\n",
      "Epoch 30/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2709 - val_loss: 0.2729\n",
      "Epoch 31/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2697 - val_loss: 0.2728\n",
      "Epoch 32/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2704 - val_loss: 0.2730\n",
      "Epoch 33/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2701 - val_loss: 0.2728\n",
      "Epoch 34/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2698 - val_loss: 0.2731\n",
      "Epoch 35/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2706 - val_loss: 0.2727\n",
      "Epoch 36/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2700 - val_loss: 0.2727\n",
      "Epoch 37/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2698 - val_loss: 0.2729\n",
      "Epoch 38/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2705 - val_loss: 0.2728\n",
      "Epoch 39/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2705 - val_loss: 0.2728\n",
      "Epoch 40/40\n",
      "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - loss: 0.2700 - val_loss: 0.2729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x52b611ee0>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_ae.fit(X_train, X_train,\n",
    "                epochs=40,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrozenConvEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.encoder.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.62      0.60      0.61      1000\n",
      "           3       0.81      0.85      0.83      1000\n",
      "           4       0.66      0.68      0.67      1000\n",
      "           5       0.94      0.92      0.93      1000\n",
      "           6       0.46      0.39      0.42      1000\n",
      "           7       0.91      0.94      0.92      1000\n",
      "           8       0.95      0.95      0.95      1000\n",
      "           9       0.93      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "frozen_conv_ae = FrozenConvEncoder(encoder=conv_ae.encoder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(dataset_name=utils.Dataset_Select.F_MNIST.value, with_val=False)\n",
    "\n",
    "pipeline_log_reg = Pipeline([\n",
    "    ('frozen_conv_ae', frozen_conv_ae),\n",
    "    ('log_reg', LogisticRegression(max_iter=5000, solver=\"newton-cg\"))\n",
    "])\n",
    "\n",
    "pipeline_log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_log_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.98      0.97       980\n",
    "           1       0.97      0.99      0.98      1135\n",
    "           2       0.94      0.94      0.94      1032\n",
    "           3       0.92      0.95      0.93      1010\n",
    "           4       0.95      0.95      0.95       982\n",
    "           5       0.93      0.91      0.92       892\n",
    "           6       0.96      0.95      0.95       958\n",
    "           7       0.95      0.92      0.94      1028\n",
    "           8       0.93      0.93      0.93       974\n",
    "           9       0.92      0.92      0.92      1009\n",
    "\n",
    "    accuracy                           0.94     10000\n",
    "   macro avg       0.94      0.94      0.94     10000\n",
    "weighted avg       0.94      0.94      0.94     10000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def evaluate_conv_autoencoder(dataset_name, params, create_plain_ae_fun, create_ae_from_params_fun):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(dataset_name=dataset_name, with_val=False)\n",
    "\n",
    "    keras_reg = KerasRegressor(\n",
    "        model=create_plain_ae_fun,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        optimizer__learning_rate=0.001,\n",
    "        model__latent_dim=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    grid_search = GridSearchCV(keras_reg, params, refit=False, cv=7, n_jobs=-1)\n",
    "    grid_search.fit(X_train, X_train)\n",
    "\n",
    "    print(grid_search.best_score_, grid_search.best_params_)\n",
    "\n",
    "    X_train_s, X_val_s, _, _, _, _ = utils.get_dataset_for_ae(dataset_name=dataset_name, with_val=True)\n",
    "\n",
    "    ae = create_ae_from_params_fun(grid_search.best_params_)\n",
    "    ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=grid_search.best_params_[\"optimizer__learning_rate\"]), loss=keras.losses.BinaryCrossentropy)\n",
    "    ae.fit(X_train_s, X_train_s,\n",
    "                epochs=grid_search.best_params_[\"epochs\"],\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val_s, X_val_s))\n",
    "    \n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2025-01-03 07:21:01.541260: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0] vs. [6272,384]\n",
      "\t [[{{function_node __inference_one_step_on_data_202248}}{{node adam/truediv_13}}]]\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mwardynski/Documents/ds/_semestr_9/uczenie_maszynowe/labs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*urllib3.*LibreSSL.*\")\n",
    "\n",
    "param_grid = {\n",
    "    'model__latent_dim': [10, 64, 128, 192],\n",
    "    'optimizer__learning_rate': [0.0001, 0.005, 0.001],\n",
    "    'epochs': [40]\n",
    "}\n",
    "\n",
    "evaluated_conv_ae = evaluate_conv_autoencoder(utils.Dataset_Select.F_MNIST.value, param_grid, create_conv_ae_as_sequence, create_conv_ae_from_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE\n",
    "\n",
    "Nieudane próby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(784)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*64, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            tf.keras.layers.Reshape(target_shape=(784)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = self.prepare_encoder()\n",
    "        self.decoder = self.prepare_decoder()\n",
    "\n",
    "    def prepare_encoder(self):\n",
    "        input_img = tf.keras.layers.Input(shape=(784,))\n",
    "        x = tf.keras.layers.Reshape(target_shape=(28, 28, 1))(input_img)\n",
    "        x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(self.latent_dim + self.latent_dim)(x)\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(x)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "        return  tf.keras.Model([input_img], [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    def prepare_decoder(self):\n",
    "        input = tf.keras.layers.Input(shape=(self.latent_dim,))\n",
    "        x = tf.keras.layers.Dense(units=7*7*64, activation=tf.nn.relu)(input)\n",
    "        x = tf.keras.layers.Reshape(target_shape=(7, 7, 64))(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same',activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same',activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation=tf.nn.sigmoid)(x) \n",
    "        x = tf.keras.layers.Reshape(target_shape=(784,))(x)\n",
    "        return  tf.keras.Model([input], [x], name=\"decoder\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        self.add_loss(self.kl_loss(z_mean, z_log_var))\n",
    "        return reconstructed\n",
    "\n",
    "    def kl_loss(self, z_mean, z_log_var):\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        return tf.reduce_mean(kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.sampling_layer = Sampling()\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Input(shape=(784,)),\n",
    "                tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                    activation='relu'),\n",
    "                # No activation\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "                tf.keras.layers.Reshape(target_shape=(784,))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = tf.split(self.encoder(inputs), num_or_size_splits=2, axis=1)\n",
    "        z = self.sampling_layer([z_mean, z_log_var])\n",
    "        reconstructed = self.decoder(z)\n",
    "        self.add_loss(self.kl_loss(z_mean, z_log_var))\n",
    "        return reconstructed\n",
    "\n",
    "\n",
    "    def kl_loss(self, z_mean, z_log_var):\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        return tf.reduce_mean(kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(64)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "vae.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy())\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utils.get_dataset_for_ae(utils.Dataset_Select.MNIST.value, with_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(-1, 784)\n",
    "# X_val = X_val.reshape(-1, 784)\n",
    "\n",
    "vae.fit(X_train, X_train,\n",
    "                epochs=3,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrozenVEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        z_mean, z_log_var = tf.split(self.encoder.predict(X), num_or_size_splits=2, axis=1)\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "frozen_vencoder = FrozenEncoder(encoder=vae.encoder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = utils.get_dataset_for_ae(dataset_name=utils.Dataset_Select.MNIST.value, with_val=False)\n",
    "\n",
    "pipeline_log_reg = Pipeline([\n",
    "    ('frozen_vencoder', frozen_vencoder),\n",
    "    ('log_reg', LogisticRegression(max_iter=2000, solver=\"newton-cg\"))\n",
    "])\n",
    "\n",
    "pipeline_log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline_log_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
